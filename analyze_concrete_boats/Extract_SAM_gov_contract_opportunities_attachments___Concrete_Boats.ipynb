{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from urllib.parse import urlparse, unquote\n",
        "from pathlib import Path\n",
        "\n",
        "def process_opportunities(api_key, posted_from, posted_to, output_dir='attachments'):\n",
        "    \"\"\"\n",
        "    Fetch and process opportunities, returning structured data and downloading attachments\n",
        "    \"\"\"\n",
        "    opportunities = []\n",
        "    base_url = \"https://api.sam.gov/prod/opportunities/v2/search\"\n",
        "\n",
        "    params = {\n",
        "        'api_key': api_key,\n",
        "        'limit': 1000,\n",
        "        'postedFrom': posted_from,\n",
        "        'postedTo': posted_to,\n",
        "        'ptype': 'u,p,a,r,s,o,k,i',\n",
        "        'organizationCode': \"070\"\n",
        "        # u= Justification (J&A)\n",
        "        # p = Pre solicitation\n",
        "        # a = Award Notice\n",
        "        # r = Sources Sought\n",
        "        # s = Special Notice\n",
        "        # o = Solicitation\n",
        "        # k = Combined Synopsis/Solicitation\n",
        "        # i = Intent to Bundle Requirements (DoD-Funded)\n",
        "        # https://open.gsa.gov/api/get-opportunities-public-api/\n",
        "        # included all except g = Sale of Surplus Property\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        results = response.json()\n",
        "\n",
        "        # Create output directory if it doesn't exist\n",
        "        Path(output_dir).mkdir(exist_ok=True)\n",
        "\n",
        "        for opp in results.get('opportunitiesData', []):\n",
        "\n",
        "            # Process attachments\n",
        "            resource_links = opp.get('resourceLinks', [])\n",
        "            downloaded_files = []\n",
        "\n",
        "            if resource_links:\n",
        "                # Limit to first 5 attachments\n",
        "                for index, url in enumerate(resource_links[:5]):\n",
        "                    try:\n",
        "                        response = requests.get(url, stream=True)\n",
        "                        response.raise_for_status()\n",
        "\n",
        "                        # Create filename\n",
        "                        original_filename = response.headers['Content-Disposition'][21:]\n",
        "                        noticeId = opp.get('noticeId', 'N/A')\n",
        "                        filename = f\"{noticeId}){sanitize_filename(original_filename)}\"\n",
        "\n",
        "                        # base_filename = f\"{sanitize_filename(opp['title'])}_{opp['noticeId']}_doc{index+1}\"\n",
        "\n",
        "#                         # Get extension from response\n",
        "#                         content_type = response.headers.get('content-type', '')\n",
        "#                         ext = get_file_extension(response)\n",
        "#                         filename = f\"{base_filename}{ext}\"\n",
        "\n",
        "\n",
        "                        # Save file\n",
        "                        filepath = Path(output_dir) / filename\n",
        "                        with open(filepath, 'wb') as f:\n",
        "                            for chunk in response.iter_content(chunk_size=8192):\n",
        "                                if chunk:\n",
        "                                    f.write(chunk)\n",
        "\n",
        "                        downloaded_files.append(filename)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error downloading attachment {index+1}: {e}\")\n",
        "\n",
        "            # Structure the opportunity data\n",
        "            opportunity = {\n",
        "                'title': opp.get('title', 'Untitled'),\n",
        "                'noticeId': opp.get('noticeId', 'N/A'),\n",
        "                'postedDate': opp.get('postedDate', 'N/A'),\n",
        "                'office': opp.get('fullParentPathName', 'Not specified'),\n",
        "                'attachments': len(resource_links) if resource_links else 0,\n",
        "                'downloadedFiles': downloaded_files\n",
        "            }\n",
        "\n",
        "            opportunities.append(opportunity)\n",
        "\n",
        "        return opportunities\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing opportunities: {e}\")\n",
        "        return []\n",
        "\n",
        "def sanitize_filename(filename):\n",
        "    \"\"\"Remove invalid characters from filename\"\"\"\n",
        "    return re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n",
        "\n",
        "# def get_file_extension(response):\n",
        "#     \"\"\"Determine file extension from response headers\"\"\"\n",
        "#     content_type = response.headers.get('content-type', '')\n",
        "#     if 'application/pdf' in content_type:\n",
        "#         return '.pdf'\n",
        "#     elif 'application/msword' in content_type:\n",
        "#         return '.doc'\n",
        "#     elif 'application/vnd.openxmlformats-officedocument.wordprocessingml.document' in content_type:\n",
        "#         return '.docx'\n",
        "#     elif 'text/plain' in content_type:\n",
        "#         return '.txt'\n",
        "#     return '.pdf'  # Default to PDF if unknown\n",
        "\n",
        "def main():\n",
        "    #api_key = \"\"\n",
        "    api_key=userdata.get('SAM_API_KEY')\n",
        "    posted_from = \"05/01/2024\"\n",
        "    posted_to = \"05/30/2024\"\n",
        "\n",
        "    opportunities = process_opportunities(api_key, posted_from, posted_to)\n",
        "\n",
        "    # Save structured data to JSON\n",
        "    with open('opportunities_2.json', 'w') as f:\n",
        "        json.dump(opportunities, f, indent=2)\n",
        "\n",
        "    print(f\"Processed {len(opportunities)} opportunities\")\n",
        "    print(\"Data saved to opportunities_2.json\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "o5EYs6WPbwBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# Load the opportunities JSON data\n",
        "with open('opportunities_2.json', 'r') as json_file:\n",
        "    opportunities = json.load(json_file)\n",
        "\n",
        "# Extract all noticeIds from opportunities.json\n",
        "notice_ids_to_find = {opportunity['noticeId'] for opportunity in opportunities}\n",
        "\n",
        "# Dictionary to store found descriptions\n",
        "notice_descriptions = {}\n",
        "\n",
        "# URL of the CSV file\n",
        "csv_url = \"https://sam.gov/api/prod/fileextractservices/v1/api/download/Contract%20Opportunities/datagov/ContractOpportunitiesFullCSV.csv?privacy=Public\"\n",
        "\n",
        "try:\n",
        "    # Download the CSV data\n",
        "    response = requests.get(csv_url)\n",
        "    response.raise_for_status()  # Raise exception for 4XX/5XX responses\n",
        "\n",
        "    # Read the CSV content from the response\n",
        "    csv_content = StringIO(response.text)\n",
        "\n",
        "    # Process the CSV data\n",
        "    csv_reader = csv.DictReader(csv_content)\n",
        "    for row in csv_reader:\n",
        "        if row['NoticeId'] in notice_ids_to_find:\n",
        "            notice_descriptions[row['NoticeId']] = row['Description']\n",
        "            # If we've found all the noticeIds we need, we can stop reading the CSV\n",
        "            if len(notice_descriptions) == len(notice_ids_to_find):\n",
        "                break\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading CSV: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# Update opportunities with descriptions\n",
        "for opportunity in opportunities:\n",
        "    notice_id = opportunity['noticeId']\n",
        "    if notice_id in notice_descriptions:\n",
        "        opportunity['description'] = notice_descriptions[notice_id]\n",
        "    else:\n",
        "        opportunity['description'] = \"\"  # Add empty description if no match found\n",
        "\n",
        "# Save the updated opportunities\n",
        "with open('updated_opportunities_2.json', 'w') as json_file:\n",
        "    json.dump(opportunities, indent=2, fp=json_file)\n",
        "\n",
        "print(f\"Successfully updated {len(notice_descriptions)} out of {len(notice_ids_to_find)} opportunities with descriptions\")"
      ],
      "metadata": {
        "id": "acxoY-4SgGjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a folder in the root directory\n",
        "!mkdir -p \"/content/drive/My Drive/attachments_2026_01_21_2\"\n",
        "\n",
        "!cp -r \"/content/attachments/\" \"/content/drive/My Drive/attachments_2026_01_21_2\"\n",
        "\n",
        "# directory = \"/content/attachments/\"\n",
        "# for filename in os.listdir(directory):\n",
        "#     f = os.path.join(directory, filename)\n",
        "#     # check if current path is a file\n",
        "#     if os.path.isfile(f):\n",
        "#         print(f)"
      ],
      "metadata": {
        "id": "qCvibwcfkU1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf \"/content/attachments/\"\n",
        "# !rm -rf \"/content/opportunities.json\"\n",
        "# !rm -rf \"/content/updated_opportunities.json"
      ],
      "metadata": {
        "id": "Zp59uM2YbIkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp -r \"/content/drive/My Drive/attachments_2025_03_03\" \"/content/attachments/\"\n"
      ],
      "metadata": {
        "id": "q9P8X7-coDqC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}